
gpmodel:
  hyperpars:
    noise_std: 
      value: 0.01 # Homoscedastic noise, standard deviation
    optimization:
      Nrestarts: 1
      # algo_name: 'LN_BOBYQA'
      Nmax_evals: 200 # Max number of function evaluations

## Standard GP parameters
gpclassimodel:
  hyperpars:
    noise_std: 
      value: 0.01 # Homoscedastic noise, standard deviation
    optimization:
      Nrestarts: 1
      # algo_name: 'LN_BOBYQA'
      Nmax_evals: 200 # Max number of function evaluations

## GPCR parameters
gpcr_model:
  hyperpars:
    noise_std: 
      value: 0.01 # Homoscedastic noise, standard deviation
    optimization:
      Nrestarts: 1
      # algo_name: 'LN_COBYLA' # Internally, the name is appended to 'nlopt.', e.g., 'nlopt.LN_COBYLA'. See https://nlopt.readthedocs.io/en/latest/NLopt_Python_Reference/
      Nmax_evals: 200 # Max number of function evaluations
  discard_too_close_points: False

  ## Expectation propagation
  ep:
    maxiter: 15 # Stopping criterion: max number of EP iterations
    prec: 1e-8 # Stopping criterion: relative precission in the logZ
    verbo: False

## Optimize acquisition function
acquisition_function:
  optimization:
    Nrestarts: 3
    # algo_name: 'LN_COBYLA' # Internally, the name is appended to 'nlopt.', e.g., 'nlopt.LN_COBYLA'. See https://nlopt.readthedocs.io/en/latest/NLopt_Python_Reference/
    disp_info_scipy_opti: False # Display info about the progress of the scipy optimizer
  prob_satisfaction: 0.90 # User-defined probability threshold (TODO: Is this really needed?)

plot:
  plotting: True
  saving: False
  path: "./plots/toy_example" # This will automatically be appended to ${hydra.run.dir} by hydra
  block: False

NBOiters: 2
Nrep: 1
with_noise: False
Ninit_points:
  total: 
  safe: 1
  unsafe: 1

